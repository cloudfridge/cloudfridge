Data Repository
=

Cloudfridge uses the sMAP Archiver Daemon (ARD) as its Data Repository.

sMAP is a set of tools for building, organizing, and querying large repositories of 
physical data organized as time series developed by UC Berkeley.

sMAP official page: https://code.google.com/p/smap-data/

Our Data Repository uses only the *Archiver* and the time series datastore *ReadingDB*.
The sMAP archiver has been selected because:
- robust time series datastore forlarge amount data without performance degradation
- no-sql document model based on tags and JSON formatted documents
- extensive and powerful query language
- HTTP API for all operations

For storing sensors data in the ARD Data Repository, Cloudfridge Redshift boards use
the Cometa infrastructure with data posted directly in JSON format into ARD 
by means of the Cometa upstream communication API and Webhooks.

A Postgres database is used by the Archiver as key-value store for metadata
and for other administrative tables to use with the sMAP front-end *PowerDB*.

Cloudfridge device profile
==

Cloudfridge uses a common profile to represent both the individual devices
and the streams of sensors' data (sources) generated by the Redshift board and 
uploaded in the Data Repository.

The primitive streams represented in a device profile are Timeseries. Timeseries
consist of sequences of readings from a single sensor and associated metadata.

Sensors in a Redshift board are:
- temperature
- humidity
- power
- door opening
- other sensors (GPIO or 1-Wire)

Time series may be organized into Collections, representing logical organizations 
of the sensors. In our case a Cloudfridge (Redshift) unit is represented by a Collection
of the Timeseries containing data from its sensors.

Metadata are added to either Timeseries or Collections. The only objects represented
in the Data Repository are Timeseries and Collections. Timeseries are durably 
identified by UUIDs.

CF Metadata
===

Metadata only has meaning when it is attached to data, that is one or more 
time-value pairs (data points). Each data point is logically considered to be 
attached to a full set of metadata.

Metadata is inherited within a source: the metadata for any data
point consists of the Metadata for that Timeseries, along with the Meta-
data all Collections in the recursive parent set. If the same piece of meta-
data is present at multiple places, the metadata "closest" to the Timeseries
(i.e., deepest in the tree) is used.

Since the Metadata can only apply to actual data readings, there is never an 
ambiguity about which piece of metadata applies to a point, and it is always 
safe to re-send all metadata for a device.

Redshift data sources:
- cabin_temperature
- evaporator_temperature
- ambient_temperature
- ambient_humidity
- compressor_power
- evaporatorfan_power
- defrost_power
- door_status

Not all data sources may be present. For instance a non-freezer refrigerator
would not have a defrost unit.

Other data sensors from GPIO or 1-Wire devices may be present in some units 
and they will have their own stream. The Collection/Timeseries structure
using metadata and not a fixed SQL schema, allows for new data stream to
be added or removed on a specific unit.

For data source in Redshift a UUID is generated.

`To generate a stream UUID from the console:

$ echo 'require "securerandom.rb"; SecureRandom.uuid' | irb
"3cc77ab0-ad88-41e0-a122-60fbe1074a5b"`

Metadata in the Collection, which represent properties of a specific unit are:

Metadata/SourceName

Metadata/Device/DeviceID
Metadata/Device/Name
Metadata/Device/MAC
Metadata/Device/Model
Metadata/Device/Version

Metadata/Sensor/Type 
Metadata/Sensor/Model
Metadata/Sensor/Version
Metadata/Sensor/SerialNumber
Metadata/Sensor/Interface

Metadata/Location/Description
Metadata/Location/Street
Metadata/Location/City
Metadata/Location/State
Metadata/Location/Zip
Metadata/Location/Lat
Metadata/Location/Lon

Metadata/Refrigerator/Manufacturer
Metadata/Refrigerator/Model
Metadata/Refrigerator/Type ["cooler", "freezer", "walkin-cooler", "walkin-freezer"]
Metadata/Refrigerator/Volume
Metadata/Refrigerator/Method

Properties/Timezone
Properties/UnitofMeasure
Properties/ReadingType  ["double","long","string"]

Description
uuid
Readings

Path:
/cloudfridge/<Device_ID>/<Sensor__Type>
NOTE: do paths need to be unique? 

Menu based on these tags:
`["Metadata/Location/Description", "Metadata/Device/Name", "Metadata/Sensor/Type"]`

`{
 "/cloudfridge/T-002/compressor_power": {
    "Properties":{
		"Timezone":"America/Los_Angeles",
		"UnitofMeasure":"kWh",
		"ReadingType":"double"
	},
	"uuid":"6225f168-c127-4b53-8bc1-a212b952e387",
	"Readings":[[1370734162000, 447.0],[1370734262000, 47.0],[1370734362000, 250.2]],
	"Metadata":{
		"SourceName":"Beverage Air 100",
		"Device":{
		    "DeviceID":"T-002",
			"Model":"Redshift",
			"Name":"Beverage Air",	
			"MAC":"00:77:2B",
			"Version":"1.0"
		},
		"Sensor": {
			"Type":"Compressor power",
			"Model":"Hal Built-in",
			"Version":"1.0",
			"SerialNumber":"1",
			"Interface":"Analog"
		},
		"Location":{
			"Description":"Office Palo Alto",
			"Street":"2666 East Bayshore Rd",
			"City":"Palo Alto",
			"State":"CA",
			"Zip":"94303",
			"Lat": "37.444889",
			"Lon": "-122.118124"
		},
		"Refrigerator":{
			"Manufacturer":"Beverage Air",
			"Model":"100",
			"Type":"Cooler",
			"Volume":"1",
			"Method":"Experimental 1.0"
		}
	}
  }
}`


Data Repository HTTP API
==

ARD provides an HTTP API at port 8079.

`~$ curl http://localhost:8079/
{"Contents": ["add", "api", "republish"]}`

Top level
===
The two top level resources are add and api. 

With a subscription API key (generated with the powerdb front-end), is possible
to post valid objects to the 

http://localhost:8079/add/[key]" location. These objects should be maps whose keys are resource 
paths on the sMAP source, and whose values are Timeseries objects following the proper schema. 

The archiver daemon will return an HTTP 200 OK code if the data and tags were successfully entered into the databases.

`$ curl http://localhost:8079/api
{"Contents": ["streams", "query", "data", "next", "prev", "tags", "operators"]}`

ARD Query API
===
The query resource is used to discover what tags are present. Called with no arguments, 
it returns a list of distinct tags which are known about. If one of those tag values is 
appended to the path, it will return a list of distinct tag values.

`$ curl http://localhost:8079/api/query
["Metadata/Location/City", "Metadata/SourceName", "Path", "Properties/ReadingType", 
"Properties/Timezone", "Properties/UnitofMeasure"]`

The only special tag is the uuid tag; it will return the uuid of streams matching the query.

To avoid generating a huge result set, it's possible to request the tags for a particular 
stream by specifying a uuid; that's guaranteed to match only one stream.

`$ curl http://localhost:8079/api/tags/uuid/a24325e6-1d7d-11e2-ad69-a7c2fa8dba6a
[
  {
    "Metadata": {
      "Location": {
        "City": "Palo Alto"
      }, 
      "Source Name": "Office Fridge1"
    }, 
    "Path": "/cloudfridge/channel0", 
    "Properties": {
      "ReadingType": "double", 
      "Timezone": "America/Los_Angeles", 
      "UnitofMeasure": "Watt"
    }, 
    "uuid": "a24325e6-1d7d-11e2-ad69-a7c2fa8dba6a"
  }
]`

`$ curl 'http://localhost:8079/api/data/uuid/d24325e6-1d7d-11e2-ad69-a7c2fa8dba61?starttime=1370571900000&endtime=1370714766000'
[
  {
    "Readings": [ 
      [
        1370646598000.0, 
        333.0
      ], 
      [
        1370646798000.0, 
        242.0
      ], 
      [
        1370646898000.0, 
        333.0
      ], 
      [
        1370647397000.0, 
        10.0
      ], 
      [
        1370647398000.0, 
        11.0
      ]
    ], 
    "uuid": "d24325e6-1d7d-11e2-ad69-a7c2fa8dba61"
  }
]`

The Archiver Daemon (ARD) HTTP API is documented at the location:

https://code.google.com/p/smap-data/wiki/ArdApi

ARD Query Language
===

For more complicated queries, a simple query language is available in ARD.

The language supports select, delete, and set operations; there is no need to refer to particular 
table since there is only one flat datastore. The select operation may be performed by anyone, and by 
default queries all public streams; the mutation operations delete and set will only operate on 
streams where the request includes an API key.

Queries can be executed in two ways:
- as body of a POST request to http://localhost:8079/api/query
- using the interactive tool, smap-query

`smap >select distinct Metadata/SourceName
http://localhost:8079/api/query?
[
  "2666 East Bayshore"
1 (3 ms)
]`

`smap > select distinct Metadata/Location/City
http://localhost:8079/api/query?
[
  "Palo Alto"
1 (5 ms)
]`

`smap > select data before now limit 1 where Metadata/SourceName = "2666 East Bayshore"
http://localhost:8079/api/query?
[
  {
    "Readings": [
      [
        "Fri Jun  7 23:23:18 2013", 
        11.0
      ]
    ], 
    "uuid": "d24325e6-1d7d-11e2-ad69-a7c2fa8dba61"
  }, 
  {
    "Readings": [
      [
        "Sat Jun  8 16:55:29 2013", 
        333.0
      ]
    ], 
    "uuid": "a24325e6-1d7d-11e2-ad69-a7c2fa8dba61"
  }
2 (6 ms)
]`

`smap >select data in (now -2hours, now) where uuid="a24325e6-1d7d-11e2-ad69-a7c2fa8dba61"
http://localhost:8079/api/query?
[
  {
    "Readings": [
      [
        "Sat Jun  8 16:50:29 2013", 
        333.0
      ], 
      [
        "Sat Jun  8 16:53:43 2013", 
        142.0
      ], 
      [
        "Sat Jun  8 16:55:23 2013", 
        142.0
      ], 
      [
        "Sat Jun  8 16:55:29 2013", 
        333.0
      ]
    ], 
    "uuid": "a24325e6-1d7d-11e2-ad69-a7c2fa8dba61"
  }
1 (5 ms)
]`

Full documentation at the location:

https://code.google.com/p/smap-data/wiki/ArdQuery

The query language allows you to optionally filter the time-series data before returning it to the client.
This is similar to a "Reduce" function in a "Map-Reduce" query.

For more information on ARD Operators:

https://code.google.com/p/smap-data/wiki/ArdOperators

ARD DB tables
===

`$ psql -p 5432 -h localhost -U archiver -W archiver`

`archiver=> \dt`
                   List of relations
 Schema |            Name            | Type  |  Owner   
-------:|:--------------------------:|-------|----------|
 public | alert_action               | table | archiver
 public | alert_alert                | table | archiver
 public | alert_check                | table | archiver
 public | alert_level                | table | archiver
 public | alert_log                  | table | archiver
 public | alert_recipients           | table | archiver
 public | alert_recipients_groups    | table | archiver
 public | alert_recipients_users     | table | archiver
 public | auth_group                 | table | archiver
 public | auth_group_permissions     | table | archiver
 public | auth_message               | table | archiver
 public | auth_permission            | table | archiver
 public | auth_user                  | table | archiver
 public | auth_user_groups           | table | archiver
 public | auth_user_user_permissions | table | archiver
 public | django_admin_log           | table | archiver
 public | django_content_type        | table | archiver
 public | django_session             | table | archiver
 public | smap_menutag               | table | archiver
 public | smap_menuvalue             | table | archiver
 public | smap_tree                  | table | archiver
 public | stream                     | table | archiver
 public | subscription               | table | archiver
 public | subscription_can_view      | table | archiver
 
(24 rows)

